# This is a Databricks asset bundle definition for dab_test.
# See https://docs.databricks.com/dev-tools/bundles/index.html for documentation.
bundle:
  name: dab_test_bt

include:
  - resources/*.yml

integration_test: &integration_test
  resources:
    jobs:
      integration_test:
        name: '[${bundle.environment}] integration_test_btafur'

        schedule:
          quartz_cron_expression: '44 37 8 * * ?'
          timezone_id: Europe/Amsterdam

        email_notifications:
          on_failure:
            - bruno.tafur@databricks.com

        tasks:
          - task_key: setup_test
            job_cluster_key: job_cluster
            notebook_task:
              notebook_path: src/notebook.ipynb
          - task_key: run_job
            run_job_task:
              job_id: ${resources.jobs.dab_test_job.id}
            depends_on:
              - task_key: setup_test
          - task_key: validate_dataset
            job_cluster_key: job_cluster
            notebook_task:
              notebook_path: src/integration_tests/validate_dataset.ipynb
            depends_on:
              - task_key: run_job

        job_clusters:
          - job_cluster_key: job_cluster
            new_cluster:
              spark_version: 13.3.x-scala2.12
              node_type_id: i3.xlarge
              policy_id: E060384AFC00043E
              aws_attributes:
                  instance_profile_arn: arn:aws:iam::997819012307:instance-profile/shard-demo-s3-access
                  zone_id: auto
              autoscale:
                  min_workers: 1
                  max_workers: 4

targets:
  # The 'dev' target, used for development purposes.
  # Whenever a developer deploys using 'dev', they get their own copy.
  dev:
    # We use 'mode: development' to make sure everything deployed to this target gets a prefix
    # like '[dev my_user_name]'. Setting this mode also disables any schedules and
    # automatic triggers for jobs and enables the 'development' mode for Delta Live Tables pipelines.
    mode: development
    default: true
    workspace:
      host: https://e2-demo-west.cloud.databricks.com

  # Optionally, there could be a 'staging' target here.
  # (See Databricks docs on CI/CD at https://docs.databricks.com/dev-tools/bundles/index.html.)
  # 
  qa:
    workspace:
      host: https://e2-demo-west.cloud.databricks.com
    <<: *integration_test


  # The 'prod' target, used for production deployment.
  prod:
    # For production deployments, we only have a single copy, so we override the
    # workspace.root_path default of
    # /Users/${workspace.current_user.userName}/.bundle/${bundle.target}/${bundle.name}
    # to a path that is not specific to the current user.
    mode: production 
    workspace:
      host: https://e2-demo-west.cloud.databricks.com
      root_path: /Shared/.bundle/prod/${bundle.name}
    run_as:
      # This runs as bruno.tafur@databricks.com in production. Alternatively,
      # a service principal could be used here using service_principal_name
      # (see Databricks documentation). 
      user_name: bruno.tafur@databricks.com
    